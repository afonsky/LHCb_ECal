{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import RBF, ConstantKernel, Product\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from skopt import gp_minimize\n",
    "from time import sleep\n",
    "import docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глобальные Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые n_initial_points модель не обучается\n",
    "n_initial_points = 5\n",
    "\n",
    "# число итераций цикла\n",
    "n_calls = 3\n",
    "\n",
    "# оптимизация на кубе [low_constraint, high_constraint]^dim\n",
    "low_constraint, high_constraint = 10., 420.\n",
    "dim = 2\n",
    "\n",
    "# столько контейнеров вызываются для параллельной работы\n",
    "batch_size = 2\n",
    "\n",
    "# директория на сервере, хранит директории, которые будут монтироваться в контейнеры\n",
    "folder_local = '/home/matyushinleonid/lhcb_ecal/feb_meeting/folder_local'\n",
    "\n",
    "# директория для файлов input и output внутри контейнера\n",
    "folder_container = '/home/nb_user/logs'\n",
    "\n",
    "# python-клиент докера\n",
    "client = docker.from_env()\n",
    "\n",
    "# имя образа\n",
    "container = \"calorbuild\"\n",
    "\n",
    "# имена директорий, каждая соответствует своей копии образа\n",
    "worker_names = ['first_worker', 'second_worker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Product(ConstantKernel(1), RBF(1)) + ConstantKernel(1)\n",
    "\n",
    "model = GaussianProcessRegressor(alpha=0, \n",
    "                                 normalize_y=True, \n",
    "                                 noise='gaussian', \n",
    "                                 n_restarts_optimizer=10, \n",
    "                                 kernel=kernel)\n",
    "\n",
    "optimizer = Optimizer([[low_constraint, high_constraint]]*dim,\n",
    "                      model,\n",
    "                      n_initial_points=n_initial_points,\n",
    "                      acq_func='EI',\n",
    "                      acq_optimizer='lbfgs',\n",
    "                      random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация (+ работа с контейнерами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_input_file(worker_name, input_data):\n",
    "    file_to_write = '{}/{}/input.txt'.format(folder_local, worker_name)\n",
    "    string_to_write = ' '.join(map(str, input_data))\n",
    "    with open(file_to_write, \"w\") as file:\n",
    "        print(string_to_write,\n",
    "              file=file)\n",
    "\n",
    "def create_job(worker_name):\n",
    "    folder_to_mount = '{}/{}'.format(folder_local, worker_name)\n",
    "    client.containers.run(container,\n",
    "                          privileged=True,\n",
    "                          remove=True,\n",
    "                          detach=True,\n",
    "                          hostname='dev',\n",
    "                          tty=True,\n",
    "                          stdin_open=True,\n",
    "                          volumes={folder_to_mount: {'bind': folder_container,\n",
    "                                                     'mode': 'rw'}})\n",
    "\n",
    "def read_output_file(worker_name):\n",
    "    file_to_read = '{}/{}/output.txt'.format(folder_local, worker_name)\n",
    "    with open(file_to_read, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "    return float(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f05f07fcbd42769e4e894f3fed5be7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n_calls)):\n",
    "    X = optimizer.ask(n_points=batch_size)\n",
    "    for i, worker_name in enumerate(worker_names):\n",
    "        x = X[i]\n",
    "        write_input_file(worker_name, x)\n",
    "        create_job(worker_name)\n",
    "    \n",
    "    sleep(3 * 60)\n",
    "    \n",
    "    Y = []\n",
    "    for i, worker_name in enumerate(worker_names):\n",
    "        y = read_output_file(worker_name)\n",
    "        Y.append(y)\n",
    "        \n",
    "    optimizer.tell(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel with multiproccesing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Pool, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_do_job(q_in, q_out):\n",
    "    while True:\n",
    "        data = q_in.get()\n",
    "        create_job() #??        \n",
    "        result = read_output_file() #?? Do one file\n",
    "        q_out.put(result)        \n",
    "    return     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(batch_size) \n",
    "m = Manager()\n",
    "q_in = m.Queue()\n",
    "q_out = m.Queue()\n",
    "pool.starmap_async(worker_do_job, [(q_in, q_out)]*batch_size)\n",
    "\n",
    "X = optimizer.ask(n_points=batch_size)\n",
    "for i in range(batch_size):\n",
    "    inp = write_input_file(worker_name, X[i]) #??\n",
    "    q_in.put(inp)\n",
    "\n",
    "for i in tqdm(range(n_calls-batch_size)): \n",
    "    x, y  = q_out.get()\n",
    "    optimizer.tell(x, y)\n",
    "    \n",
    "    inp_path_file = write_input_file(optimizer.ask()) #??\n",
    "    q_in.put(inp_path_file)\n",
    "    \n",
    "for i in range(batch_size):\n",
    "    x, y  = q_out.get()\n",
    "    optimizer.tell(x, y)        \n",
    "    \n",
    "pool.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
